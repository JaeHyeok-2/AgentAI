You are an AI scientist.

A user has asked the following question:
"I used an AI that could detect things like people, cars, and traffic lights all at once in a single photo. Even small items like backpacks weren’t missed. How can such compact models handle so many object types at once?"

Based on the following recommended models, explain:

1. What task the user is trying to perform.
2. How the model(s) would work in a CNAPS AI-like workflow (input → model → output).
3. List relevant papers and tools (with GitHub or ArXiv links) that support your answer.

Use **only the provided models and papers**. Do not refer to outside sources.

### Recommended AI Models:
Model: ObjDet-HuggingFace-hustvl-yolos-small
Paper: None

### Related Papers:
Model: SurfaceAug: Closing the Gap in Multimodal Ground Truth Sampling
Paper: http://arxiv.org/pdf/2312.03808v1.pdf
Summary: Despite recent advances in both model architectures and data augmentation, multimodal object detectors still barely outperform their LiDAR-only counterparts. This shortcoming has been attributed to a lack of sufficiently powerful multimodal data augmentation. To address this, we present SurfaceAug, a novel ground truth sampling algorithm. SurfaceAug pastes objects by resampling both images and point clouds, enabling object-level transformations in both modalities. We evaluate our algorithm by training a multimodal detector on KITTI and compare its performance to previous works. We show experimentally that SurfaceAug outperforms existing methods on car detection tasks and establishes a new state of the art for multimodal ground truth sampling.

Model: Object-Focused Data Selection for Dense Prediction Tasks
Paper: http://arxiv.org/pdf/2412.10032v1.pdf
Summary: While unlabeled image data is often plentiful, the costs of high-quality labels pose an important practical challenge: Which images should one select for labeling to use the annotation budget for a particular target task most effectively? To address this problem, we focus on single-pass data selection, which refers to the process of selecting all data to be annotated at once before training a downstream model. Prior methods for single-pass data selection rely on image-level representations and fail to reliably outperform random selection for object detection and segmentation. We propose Object-Focused Data Selection (OFDS) which leverages object-level features from foundation models and ensures semantic coverage of all target classes. In extensive experiments across tasks and target domains, OFDS consistently outperforms random selection and all baselines. The best results for constrained annotation budgets are obtained by combining human labels from OFDS with autolabels from foundation models. Moreover, using OFDS to select the initial labeled set for active learning yields consistent improvements

Model: EffiPerception: an Efficient Framework for Various Perception Tasks
Paper: http://arxiv.org/pdf/2403.12317v1.pdf
Summary: The accuracy-speed-memory trade-off is always the priority to consider for several computer vision perception tasks.   Previous methods mainly focus on a single or small couple of these tasks, such as creating effective data augmentation, feature extractor, learning strategies, etc. These approaches, however, could be inherently task-specific: their proposed model's performance may depend on a specific perception task or a dataset.   Targeting to explore common learning patterns and increasing the module robustness, we propose the EffiPerception framework.   It could achieve great accuracy-speed performance with relatively low memory cost under several perception tasks: 2D Object Detection, 3D Object Detection, 2D Instance Segmentation, and 3D Point Cloud Segmentation.   Overall, the framework consists of three parts:   (1) Efficient Feature Extractors, which extract the input features for each modality. (2) Efficient Layers, plug-in plug-out layers that further process the feature representation, aggregating core learned information while pruning noisy proposals. (3) The EffiOptim, an 8-bit optimizer to further cut down the computational cost and facilitate performance stability.   Extensive experiments on the KITTI, semantic-KITTI, and COCO datasets revealed that EffiPerception could show great accuracy-speed-memory overall performance increase within the four detection and segmentation tasks, in comparison to earlier, well-respected methods.


Answer:
