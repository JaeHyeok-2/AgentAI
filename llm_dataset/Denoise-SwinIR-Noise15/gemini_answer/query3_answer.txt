Based on the provided models and papers, here is the analysis of the user's question about modern AI techniques for restoring images with extreme degradation:

## 1. Task Analysis
The user is performing **advanced image restoration** from extremely degraded photos. This involves recovering clear, detailed images from inputs suffering from severe noise, blur, artifacts, and multiple types of degradation using cutting-edge AI architectures.

## 2. CNAPS AI-like Workflow (Input → Model → Output)

**Input:** Heavily degraded photos with extreme noise, blur, artifacts, and quality deterioration

**Model Processing:**
- **SwinIR (Denoise-SwinIR-Noise15)** provides the foundational restoration architecture through:
  - Swin Transformer backbone for hierarchical feature extraction
  - Window-based self-attention mechanisms for efficient long-range dependency modeling
  - Multi-scale processing capabilities for handling various degradation types
- **HAIR (Hypernetworks-based All-in-One Image Restoration)** enables dynamic adaptation via:
  - Classifier generating Global Information Vector (GIV) for degradation characterization
  - Hyper Selecting Net (HSN) producing degradation-specific parameters
  - Plug-and-play integration improving existing restoration models significantly
- **Dual Transformers approach** leverages frequency-domain insights through:
  - Degradation estimation transformer (Dformer) capturing degradation characteristics across frequency bands
  - Restoration transformer (Rformer) with degradation-adaptive self-attention modules
  - Frequency-aware processing for targeted restoration of affected components
- **DreamClear (DiT-based restoration)** utilizes advanced generative capabilities by:
  - Diffusion Transformer (DiT) architecture leveraging text-to-image generative priors
  - Multi-modal large language model (MLLM) perceptual capabilities for photorealistic restoration
  - Mixture of Adaptive Modulator (MoAM) dynamically integrating restoration experts

**Output:** Clear, detailed restored images with dramatically improved quality, reduced noise, and recovered fine details

## 3. Leading Architectures and Techniques
Current state-of-the-art approaches include:
- **Transformer-based architectures:** SwinIR and dual transformer approaches outperform traditional CNN methods
- **Hypernetwork adaptation:** HAIR enables dynamic parameter generation for specific degradation types
- **Frequency-domain processing:** Dual transformers leverage frequency decomposition for targeted restoration
- **Diffusion-based restoration:** DreamClear utilizes generative diffusion priors for photorealistic results
- **All-in-one frameworks:** Modern models handle multiple degradation types simultaneously while maintaining specialized performance

## 4. Relevant Papers and Tools

### Primary Model:
- **Model:** Denoise-SwinIR-Noise15
- **Paper:** https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/Liang_SwinIR_Image_Restoration_Using_Swin_Transformer_ICCVW_2021_paper.pdf
- **GitHub:** https://github.com/JingyunLiang/SwinIR

### Advanced Frameworks:
- **Model:** HAIR: Hypernetworks-based All-in-One Image Restoration
- **Paper:** http://arxiv.org/pdf/2408.08091v4.pdf
- **GitHub:** https://github.com/toummHus/HAIR

- **Model:** Learning Dual Transformers for All-In-One Image Restoration from a Frequency Perspective
- **Paper:** http://arxiv.org/pdf/2407.01636v2.pdf

- **Model:** DreamClear: High-Capacity Real-World Image Restoration with Privacy-Safe Dataset Curation
- **Paper:** http://arxiv.org/pdf/2410.18666v2.pdf
- **GitHub:** https://github.com/shallowdream204/dreamclear

The current leading architectures combine transformer-based processing, frequency-domain analysis, hypernetwork adaptation, and diffusion-based generative techniques to achieve remarkable restoration results from extremely degraded images.