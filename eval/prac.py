import streamlit as st
import json
import re
from pathlib import Path
import glob
import os
from collections import defaultdict

# ğŸ“‚ ê²½ë¡œ ì„¤ì •
DATA_PATH = Path("/Users/jaeyoung/kuaicv/AgentAI/output/prompts_by_model_query")
pattern = os.path.join(DATA_PATH, "**", "*.json")
json_paths = sorted(glob.glob(pattern, recursive=True))

# âœ… ëª¨ë¸ë³„ query êµ¬ì¡°í™”
query_map = defaultdict(dict)
for f in json_paths:
    path = Path(f)
    model_name = path.parts[-3]
    query_name = path.parts[-2]
    query_map[model_name][query_name] = path

# ğŸ” LLM ì´ë¦„ ë§¤í•‘
MODEL_MAP = {
    "llm_a": "claude_sonnet4",
    "llm_b": "chatgpt4o",
    "llm_c": "gemini_pro"
}

# âœ… ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ì¶œ í•¨ìˆ˜
def extract_user_question(query_text):
    match = re.search(r'["â€œ](.+?)["â€]', query_text, re.DOTALL)
    return match.group(1).strip() if match else "(ì‚¬ìš©ì ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.)"

# ğŸ§­ UI ì‹œì‘
st.set_page_config(layout="wide", page_title="AgentAI Viewer", page_icon="ğŸ§ ")
st.sidebar.title("ğŸ” Query Navigation")

# ğŸ”½ ëª¨ë¸ ì„ íƒ
selected_model = st.sidebar.selectbox("ëª¨ë¸ ì„ íƒ", list(query_map.keys()))

# ğŸ”½ ì¿¼ë¦¬ ì„ íƒ
if selected_model:
    query_names = list(query_map[selected_model].keys())
    selected_query = st.sidebar.selectbox("ì¿¼ë¦¬ ì„ íƒ", query_names)

    # ğŸ“‹ í‰ê°€ ê¸°ì¤€
    with st.sidebar.expander("ğŸ“‹ í‰ê°€ ê¸°ì¤€ ë³´ê¸°"):
        st.markdown("""
**ğŸ§ª í‰ê°€ ê¸°ì¤€ (ê° í•­ëª©ë‹¹ 10ì  ë§Œì )**

| ë²ˆí˜¸ | í•­ëª© | ì„¤ëª… |
|------|------|------|
| 1 | ëª…í™•ì„± ë° ê°€ë…ì„± | ì„¤ëª…ì´ ëª…í™•í•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ì˜ ì •ë¦¬ë˜ì—ˆëŠ”ê°€? |
| 2 | ì •í™•ì„± ë° ì™„ì „ì„± | ìš”êµ¬ëœ ëª¨ë“  í•­ëª©ì´ ë¹ ì§ì—†ì´ í¬í•¨ë˜ì—ˆëŠ”ê°€? |
| 3 | CNAPS ìŠ¤íƒ€ì¼ ì›Œí¬í”Œë¡œìš° | ë¶„ê¸°(branch), ë³‘í•©(merge) ë“± ì‹œëƒ…ìŠ¤ êµ¬ì¡°ê°€ ë°˜ì˜ë˜ì—ˆëŠ”ê°€? |
| 4 | ì œê³µ ëª¨ë¸ë§Œ ì‚¬ìš© | ë¬¸ì œì—ì„œ ì œì‹œí•œ ëª¨ë¸ë§Œì„ ì‚¬ìš©í–ˆëŠ”ê°€? |
| 5 | í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì„¤ë“ë ¥ | ì„ íƒ ëª¨ë¸ì˜ ê·¼ê±°ì™€ ì„¤ëª…ì´ ì„¤ë“ë ¥ ìˆì—ˆëŠ”ê°€? |
""")

    # ğŸ“„ JSON ë¡œë“œ
    json_path = query_map[selected_model][selected_query]
    with open(json_path, 'r') as f:
        data = json.load(f)

    query_text = data.get("query_text", "")
    responses = data.get("responses", {})
    votes = data.get("votes", {})
    majority = data.get("majority_vote", "")

    # ğŸ¯ ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ì¶œ
    user_ask = extract_user_question(query_text)

    # ğŸ¯ ì¶”ì²œ ëª¨ë¸ ëª©ë¡ ì¶”ì¶œ
    model_block_match = re.search(r"### Recommended AI Models:\s*\n(.+)", query_text, re.DOTALL)
    models_raw = model_block_match.group(1).strip() if model_block_match else "(ëª¨ë¸ ëª©ë¡ ì—†ìŒ)"
    models_clean = re.findall(r"- \*\*(.*?)\*\*\n\s*Paper: (.*)", models_raw)
    models_md = "\n".join([f"- **{name}**\n  Paper: {link}" for name, link in models_clean]) if models_clean else models_raw

    # ğŸ” ì‚¬ìš©ì ì§ˆë¬¸ ì¶œë ¥
    st.markdown("## ğŸ™‹ ì‚¬ìš©ì ì§ˆë¬¸")
    st.info(f"**\"{user_ask}\"**")

    # ğŸ“š ì¶”ì²œëœ ëª¨ë¸ ì¶œë ¥
    st.markdown("## ğŸ§  ì¶”ì²œëœ AI ëª¨ë¸ ëª©ë¡")
    st.code(models_md, language="markdown")

    # ğŸ“Š ëª¨ë¸ ì‘ë‹µ ë¹„êµ
    st.markdown("## ğŸ¤– Model Responses")
    for raw_key in ["llm_a", "llm_b", "llm_c"]:
        response = responses.get(raw_key, "(No response found)")
        mapped_name = MODEL_MAP.get(raw_key, raw_key)
        voted_by = [model for model, v in votes.items() if v == raw_key]
        majority_flag = "ğŸŒŸ **Majority Vote**" if raw_key == majority else ""

        with st.expander(f"ğŸ§  {mapped_name}", expanded=True):
            st.markdown(response, unsafe_allow_html=True)
            st.markdown(f"âœ… **Voted by**: {', '.join(voted_by) if voted_by else 'None'}")
            if majority_flag:
                st.markdown(majority_flag)
