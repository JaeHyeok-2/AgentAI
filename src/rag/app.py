import streamlit as st
import json
import time
import os
from retriever import retrieve_models_and_papers
from prompt import build_prompt
from answer import generate_answer_with_feedback

st.set_page_config(page_title="RAG ì¿¼ë¦¬ ì‹¤í–‰ê¸°", layout="centered")
st.title("ğŸ“š ëª¨ë¸ 1ê°œ + ë…¼ë¬¸ ì¶”ì²œ + GPT ì‘ë‹µ (ì„ íƒ ì‹¤í–‰)")

# ğŸ”¹ ì¿¼ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
with open("/home/cvlab/Desktop/AgentAI/dataset/model_queries_only.json", encoding="utf-8") as f:
    model_queries = json.load(f)

query_pool = []
for model in model_queries:
    model_name = model.get("Model Unique Name", "Unknown Model")
    for i in range(1, 4):
        q = model.get(f"Query{i}", "").strip()
        if q:
            query_pool.append((q, model_name))

if "use_rerank" not in st.session_state:
    st.session_state["use_rerank"] = True
use_rerank = st.checkbox("ğŸš€ Cross-Encoder Rerank ì‚¬ìš©", value=st.session_state["use_rerank"])

if "results" not in st.session_state:
    st.session_state["results"] = []

if "cache" not in st.session_state:
    st.session_state["cache"] = {}

st.markdown(f"ì´ {len(query_pool)}ê°œì˜ ì¿¼ë¦¬ì— ëŒ€í•´ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

# ğŸ”¹ ì¿¼ë¦¬ ìˆœì°¨ ì‹¤í–‰
for i, (query, model_name) in enumerate(query_pool, 1):
    query_key = f"query_{i}"
    st.markdown(f"---\n### ğŸ” Query {i}: {query}")
    st.markdown(f"ğŸ“Œ ì›ë˜ ëª¨ë¸: `{model_name}`")

    if st.button(f"ğŸ” ë¬¸ì„œ ì¶”ì²œ ì‹¤í–‰ (Query {i})"):
        with st.spinner("â³ ë¬¸ì„œ ë° ëª¨ë¸ ì¶”ì²œ ì¤‘..."):
            try:
                models, papers = retrieve_models_and_papers(query, k_models=1, k_arxiv=5, use_rerank=use_rerank)
                prompt = build_prompt(query, papers[:3])
                st.session_state["cache"][query_key] = {
                    "query": query,
                    "model_name": model_name,
                    "model": models[0] if models else None,
                    "papers": papers,
                    "prompt": prompt
                }
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")
                continue

    if query_key in st.session_state["cache"]:
        cached = st.session_state["cache"][query_key]
        selected_model = cached["model"]
        papers = cached["papers"]
        prompt = cached["prompt"]

        st.markdown("### ğŸ›  ì¶”ì²œ AI ëª¨ë¸")
        if selected_model:
            url = selected_model.get("GitHub") or selected_model.get("HuggingFace") or "#"
            st.markdown(f"- **[{selected_model['Model Unique Name']}]({url})**")
        else:
            st.markdown("_ì¶”ì²œ ëª¨ë¸ ì—†ìŒ_")

        st.markdown("### ğŸ“– ê´€ë ¨ ë…¼ë¬¸ Top 5")
        for idx, p in enumerate(papers):
            dist = p.get("dist", 0.0)
            score = p.get("score")
            score_str = f", Score={score:.3f}" if score is not None else ""
            st.markdown(f"**{idx+1}. [{p['Model Unique Name']}]({p['Paper']})** (L2={dist:.3f}{score_str})")

        st.markdown("### ğŸ“ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸")
        st.code(prompt, language="text")

        # GPT ì‹¤í–‰ ë²„íŠ¼
        if st.button(f"ğŸ¤– GPT ì‘ë‹µ ìƒì„± (Query {i})"):
            with st.spinner("LLM ì‘ë‹µ ìƒì„± ì¤‘..."):
                try:
                    answer = generate_answer_with_feedback(prompt)
                    st.success("âœ… GPT ì‘ë‹µ ìƒì„± ì™„ë£Œ")
                    st.markdown(answer)
                except Exception as e:
                    st.error(f"LLM ì˜¤ë¥˜: {e}")
                    answer = ""

            st.session_state["results"].append({
                "query": query,
                "original_model": model_name,
                "recommended_model": selected_model.get("Model Unique Name") if selected_model else None,
                "recommended_papers": [p["Model Unique Name"] for p in papers],
                "prompt": prompt,
                "answer": answer
            })

# ğŸ”¹ ê²°ê³¼ ì €ì¥
if st.session_state["results"]:
    if st.button("ğŸ’¾ ì „ì²´ ê²°ê³¼ JSON ì €ì¥"):
        save_path = "/home/cvlab/Desktop/AgentAI/output/llm_rag_results.json"
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(st.session_state["results"], f, indent=2, ensure_ascii=False)
        st.success(f"ğŸ“ ì €ì¥ ì™„ë£Œ â†’ {save_path}")